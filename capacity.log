/**
 * author：镇天宇
 * 
 * href连接爬虫，适合并发大量拉取带有过滤条件href
 * 
 * 性能问题:
 *      初期磁盘压力过大，大量的小文件块读写，机械硬盘iops跟不上(带宽只能卡在60m左右徘徊) (已解决，400mbps带宽已完全占满)
 *      初期磁盘压力过大造成php等待mysql响应，造成cpu浪费在mysql网络阻塞上 (已解决)
 *      后期update变多，insert变少，逐渐演变成抓取的带宽瓶颈，但是同样会造成cpu的网络阻塞（已解决）
 *      策略的过于复杂将直接影响cpu的效率(精简各站点Strategy文件的策略,最好先人为判断)
 *      当多策略同时运行时，大量的redis的存储于计算会导致redis的cpu到顶（redis是单进程应用），然后导致php等待redis，php负载也相应变高
 *          ->是搜狐的站点让redis负载变高，将搜狐的策略缩小即可（为何搜狐这么屌？）
 *      当增大策略的规模时，redis的内存不够用，造成swap，性能急剧下降
 *          ->还是需要缩小策略的范围。
 *          ->使用另外一台服务器redis存储，redis空间缓解        
 * 
 *          ->减小mysql所需内存，将大部分内存留给redis.(mysql的磁盘交互在大量抓取的情况下无法避免，高性能的去重优先交给redis)
 *              ->还是磁盘压力过大，只能取消记录抓取记录了。只记录内容，可以少很多次mysql交互
 *          
 *          ->提高抓取策略算法，下一步打算从a标签的特性入手（从新闻网站的连接特性）
 *              ->超链接的字数
 * 
 * 建议：
 *      针对初期磁盘压力过大，很大一部分原因是热度优先所搜导致硬盘读取，
 *           ->若热度优先搜索用redis代替则可以让抓取瓶颈变为带宽，但是redis没有想到好的解决方案
 *          (已解决,利用Redis set去重href，list来维护待抓取href，但不是热度优先搜索，变成广度优先了
 *           但是同样能抓遍全站数据，下一步需要考虑的是Redis状态码的回退问题，不过带宽顺利占满400m，io没有压力)
 * 
 *          【遇到新问题，在中后期，磁盘io又卡住了,在中后期的时候，mysql表的大小超过了innodb_buffer_pool_size（定为20G），将对磁盘做读取操作
 *           机械硬盘的机械特性在同时读取和写入时造成io严重堵塞。（解决办法为更换SSD硬盘或者是其他nosql数据库,无需维护索引的数据库。）
 *           目测解决还需一些类似于mongodb的文档数据库存储网页数据】
 *               ->【削减mysql所需数据量，让mysql的表数据小于innodb_buffer_pool_size的大小,大量字符串用mongodb存储】
 *               ->【mongodb建立索引后同样很慢，磁盘瓶颈主要体现在整个document内容的插入，应该舍弃部分内容,提取精华内容插入】
 *               ->【解决办法，扩大innodb_buffer_pool_size（暂时性），无索引的关系表分离，防止内存与硬盘做太多io交互】（已解决）
 *            
 * 
 *      若可以采用python抓取更好，应该使用epoll维持响应，Goutte库会造成响应阻塞（需要用多进程弥补）
 *      数据库建议采用Mongodb或者hbase，用mysql维持关系性，采用redis维持href去重列表（不依靠mysql的唯一键） (已解决,Mongodb暂时不需要)
 *      优先优化mysql，尽量减少表索引数量，但要保证select的迅速响应。（目前time索引没有必要，但暂时保留） 
 *           ->  利用了Redis删除了三个索引，只留一个href唯一索引)（已解决）
 *           ->  分表，href唯一索引也删除，用redis来保证唯一性
 * 
 *      IsHrefLegal函数是高频调用，在确定php的cpu计算压力过大时，优先优化此函数。(待优化，一个进程8%的单核逻辑cpu左右)
 *      在ssd硬盘上效果更好，但是抓取速度也限制在网络带宽上 (已解决)
 */